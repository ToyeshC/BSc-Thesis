{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries\n"
      ],
      "metadata": {
        "id": "yuxWP78vTuEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 -m pip install pattern\n",
        "# !python3 -m pip install krippendorff\n",
        "# !python3 -m pip install simpledorff"
      ],
      "metadata": {
        "id": "74MA7hzJT8OG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import simpledorff\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from pattern.nl import sentiment\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import vstack\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmy40IPZTtR8",
        "outputId": "6b8dfda5-6043-4e99-d0aa-52a203ac7550"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing dataset"
      ],
      "metadata": {
        "id": "fVKJUIvDTxZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx4OGRoIT0pp",
        "outputId": "f2a57403-6c75-4f73-f352-a1d9d7f0a2cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_master = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/BSc AI Thesis/comments_new.csv')"
      ],
      "metadata": {
        "id": "hHmoYKDHT203"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_master.head(10000)"
      ],
      "metadata": {
        "id": "kE31-dsMT3Vx"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "UfXH9YaCuxUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping unused features"
      ],
      "metadata": {
        "id": "MNI0qqtT9R7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unused_features = ['user_id', 'created_at', 'status', 'reply_count', 'respect_count', 'is_featured']\n",
        "df.drop(columns=unused_features, axis=1, inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "kshi1Ej_u8fL"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping comments with just links"
      ],
      "metadata": {
        "id": "v4guES3G9aqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering rows starting with 'http' and not having any blank spaces\n",
        "df_links = df[(df['text'].str[:4] == \"http\") & (~df['text'].str.contains(' '))]\n",
        "\n",
        "# Drop the filtered rows\n",
        "df.drop(df_links.index, inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "cX9F3wnW9eBZ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label distribution"
      ],
      "metadata": {
        "id": "PLTFZxy9PddY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_1 = Counter(df['Label 1'].iloc[:99])\n",
        "count_2 = Counter(df['Label 2'].iloc[:99])\n",
        "\n",
        "subjective_1 = count_1['subjective']\n",
        "objective_1 = count_1['objective']\n",
        "\n",
        "subjective_2 = count_2['subjective']\n",
        "objective_2 = count_2['objective']\n",
        "\n",
        "# Calculating the distribution\n",
        "total = subjective_1 + objective_1\n",
        "\n",
        "subjective_avg = (subjective_1 + subjective_2) / 2\n",
        "objective_avg = (objective_1 + objective_2) / 2\n",
        "\n",
        "subjective_percent = round((subjective_avg / total) * 100, 2)\n",
        "objective_percent = round((objective_avg / total) * 100, 2)\n",
        "\n",
        "# Displaying the results\n",
        "print(f\"Subjective labels: {subjective_percent}%\")\n",
        "print(f\"Objective labels: {objective_percent}%\")"
      ],
      "metadata": {
        "id": "t3NDt3CKPiZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c55bca7-5095-4590-a1c4-528d0cb96d0f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjective labels: 58.59%\n",
            "Objective labels: 41.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Krippendorff's alpha"
      ],
      "metadata": {
        "id": "kZHb-iHR4iMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Label 1', 'Label 2', 'Label 3', 'Label 4', 'Label 5', 'Label 6', 'Label 7', 'Label 8', 'Label 9', 'Label 10', 'Label 11', 'Label 12']\n",
        "\n",
        "# Calculating Krippendorff's alpha\n",
        "df_alpha = df.pivot_table(columns='comment_id', values=labels, aggfunc=\"first\")\n",
        "alpha = simpledorff.calculate_krippendorffs_alpha(df_alpha)\n",
        "\n",
        "# Displaying the result\n",
        "print(f\"Krippendorff's alpha: {round(alpha, 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5PCA3QLn9wJ",
        "outputId": "05077f62-f323-4f92-fe12-b0c72849ec3b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Krippendorff's alpha: 0.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating gold label column"
      ],
      "metadata": {
        "id": "vEi-rmjl3AG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gold Label'] = df[labels].apply(lambda row: row.value_counts().idxmax() if row.count() > 0 else None, axis=1)"
      ],
      "metadata": {
        "id": "qVMAo0v93EcX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre-processing"
      ],
      "metadata": {
        "id": "v9BziTj2UF3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokeniser = WordPunctTokenizer()\n",
        "stopwords = set(stopwords.words('dutch'))\n",
        "\n",
        "preprocessed_text = []\n",
        "\n",
        "for comment in df['text']:\n",
        "  # Normalising the comments by converting to lowercase, removing numbers and removing stopwords\n",
        "  tokens = tokeniser.tokenize(comment.lower())\n",
        "  tokens = [token for token in tokens if token.isalpha()]\n",
        "  tokens = [token for token in tokens if token not in stopwords]\n",
        "\n",
        "  preprocessed_text.append(' '.join(tokens))\n",
        "\n",
        "df['preprocessed text'] = preprocessed_text"
      ],
      "metadata": {
        "id": "88yMBoUgUIN1"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective vs. subjective: Clustering"
      ],
      "metadata": {
        "id": "VaZbs9rOURur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 1: Analysis on comment level"
      ],
      "metadata": {
        "id": "6cQAE7kXZjvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction\n",
        "vectoriser = TfidfVectorizer()\n",
        "comment_vectors = vectoriser.fit_transform(preprocessed_text)\n",
        "\n",
        "# Initial clustering based on comment\n",
        "kmeans = KMeans(n_clusters=2, n_init='auto')\n",
        "kmeans.fit(comment_vectors)\n",
        "\n",
        "cluster_labels_case_1_init = kmeans.labels_\n",
        "\n",
        "# Calculating average subjectivity for each cluster\n",
        "cluster_sentiments = {0: [], 1: []}\n",
        "\n",
        "for comment, cluster_label in zip(df['preprocessed text'], cluster_labels_case_1_init):\n",
        "  sentiment_value = sentiment(comment)[1]\n",
        "  cluster_sentiments[cluster_label].append(sentiment_value)\n",
        "\n",
        "avg_subjectivity = {label: sum(values) / len(values) for label, values in cluster_sentiments.items()}\n",
        "\n",
        "# Re-assingning clusters based on subjectivity\n",
        "subjective_cluster, objective_cluster = (0, 1) if avg_subjectivity[0] > avg_subjectivity[1] else (1, 0)\n",
        "cluster_labels_case_1 = [1 if label == subjective_cluster else 0 for label in cluster_labels_case_1_init]"
      ],
      "metadata": {
        "id": "H-z5OGa4WORx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 2: Analysis on sentence level"
      ],
      "metadata": {
        "id": "IY5A-cU8Z06c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_labels_case_2 = []\n",
        "\n",
        "for comment in df['preprocessed text']:\n",
        "  # Splitting the comment sentences into tokens\n",
        "  sentences = nltk.sent_tokenize(comment)\n",
        "\n",
        "  # Calculating subjectivity for sentences\n",
        "  subjective_values = [sentiment(sentence)[1] for sentence in sentences]\n",
        "  subjective_count = sum(1 for val in subjective_values if val > 0.5)\n",
        "  objective_count = len(subjective_values) - subjective_count\n",
        "\n",
        "  # Assigning clusters based on subjectivity\n",
        "  cluster_labels_case_2.append(1 if subjective_count > objective_count else 0)"
      ],
      "metadata": {
        "id": "7C6JIT4pXV_D"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding cluster labels to df"
      ],
      "metadata": {
        "id": "xL7FlpcBpfU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:, \"Label Clustering: Case 1\"] = pd.Series(cluster_labels_case_1, index=df.index).map({1: 'subjective', 0: 'objective'})\n",
        "df.loc[:, \"Label Clustering: Case 2\"] = pd.Series(cluster_labels_case_2, index=df.index).map({1: 'subjective', 0: 'objective'})"
      ],
      "metadata": {
        "id": "r7XrEaGqpiij"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the two cases"
      ],
      "metadata": {
        "id": "uofuNKa_x2Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the same predictions between both cases\n",
        "matches = (df['Label Clustering: Case 1'] == df['Label Clustering: Case 2']).sum()\n",
        "\n",
        "# Calculating the percentage similarity\n",
        "percentage_similarity = round((matches / len(df)) * 100, 2)\n",
        "\n",
        "# Displaying the result\n",
        "print(f\"Percentage similarity between case 1 and case 2: {percentage_similarity}%\")"
      ],
      "metadata": {
        "id": "H8-iCUM7x8K2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d31aa74-6ba6-428b-e163-86427742480b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage similarity between case 1 and case 2: 62.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing case 1 to gold labels"
      ],
      "metadata": {
        "id": "GPWo69EhyYMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Classification report for case 1 vs gold labels:\\n {classification_report(df['Gold Label'].iloc[:99], df['Label Clustering: Case 1'].iloc[:99])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rPxf2Loz4tk",
        "outputId": "6229120b-e05c-4d9d-bf43-ee8466017c01"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for case 1 vs gold labels:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   objective       0.43      0.98      0.60        42\n",
            "  subjective       0.75      0.05      0.10        57\n",
            "\n",
            "    accuracy                           0.44        99\n",
            "   macro avg       0.59      0.51      0.35        99\n",
            "weighted avg       0.61      0.44      0.31        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing case 2 to gold labels"
      ],
      "metadata": {
        "id": "gST2y_5P0BN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Classification report for case 2 vs gold labels:\\n {classification_report(df['Gold Label'].iloc[:99], df['Label Clustering: Case 2'].iloc[:99])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDOxSvkO-J0T",
        "outputId": "76532438-ede4-43ef-d1ac-a061b79d8f48"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for case 2 vs gold labels:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   objective       0.41      0.67      0.51        42\n",
            "  subjective       0.55      0.30      0.39        57\n",
            "\n",
            "    accuracy                           0.45        99\n",
            "   macro avg       0.48      0.48      0.45        99\n",
            "weighted avg       0.49      0.45      0.44        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of labels in case 1"
      ],
      "metadata": {
        "id": "nKtIBD81U6nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_case_1 = Counter(df['Label Clustering: Case 1'])\n",
        "\n",
        "subjective_count_1 = count_case_1['subjective']\n",
        "objective_count_1 = count_case_1['objective']\n",
        "total_1 = subjective_count_1 + objective_count_1\n",
        "\n",
        "subjective_percent_1 = round((subjective_count_1 / total_1) * 100, 2)\n",
        "objective_percent_1 = round((objective_count_1 / total_1) * 100, 2)\n",
        "\n",
        "# Displaying the results\n",
        "print(f\"Subjective labels case 1: {subjective_percent_1}%\")\n",
        "print(f\"Objective labels case 1: {objective_percent_1}%\")"
      ],
      "metadata": {
        "id": "eMFwS77nU_W5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e0be080-a903-4419-f95f-d3e35910537c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjective labels case 1: 26.6%\n",
            "Objective labels case 1: 73.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of labels in case 2"
      ],
      "metadata": {
        "id": "vNZdjw-4WqGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_case_2 = Counter(df['Label Clustering: Case 2'])\n",
        "\n",
        "subjective_count_2 = count_case_2['subjective']\n",
        "objective_count_2 = count_case_2['objective']\n",
        "total_2 = subjective_count_2 + objective_count_2\n",
        "\n",
        "subjective_percent_2 = round((subjective_count_2 / total_2) * 100, 2)\n",
        "objective_percent_2 = round((objective_count_2 / total_2) * 100, 2)\n",
        "\n",
        "# Displaying the results\n",
        "print(f\"Subjective labels case 2: {subjective_percent_2}%\")\n",
        "print(f\"Objective labels case 2: {objective_percent_2}%\")"
      ],
      "metadata": {
        "id": "f4tijOfOWJnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caf96cc-1329-4b09-9e7f-ac33b66487d1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjective labels case 2: 26.42%\n",
            "Objective labels case 2: 73.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective vs. subjective: Semi-supervised"
      ],
      "metadata": {
        "id": "Re7VcsvCtpd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Labeled-unlabeled split\n",
        "labeled_data = df.iloc[:99]\n",
        "unlabeled_data = df.iloc[99:]\n",
        "\n",
        "# Feature extraction\n",
        "X_labeled = vectoriser.fit_transform(labeled_data['preprocessed text'])\n",
        "y_labeled = labeled_data['Gold Label']\n",
        "X_unlabeled = vectoriser.transform(unlabeled_data['preprocessed text'])\n",
        "\n",
        "# Train-test split\n",
        "X_labeled_train, X_labeled_test, y_labeled_train, y_labeled_test = train_test_split(X_labeled, y_labeled, test_size=0.2)\n",
        "\n",
        "# Logistic regression base model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_labeled_train, y_labeled_train)\n",
        "\n",
        "# Prediciting test labels\n",
        "test_predictions = model.predict(X_labeled_test)"
      ],
      "metadata": {
        "id": "gCizh_FaOi3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Classification report:\\n {classification_report(y_labeled_test, test_predictions)}\")"
      ],
      "metadata": {
        "id": "Ud6sAOpTQZYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting labels\n",
        "unlabeled_pred = model.predict(X_unlabeled)\n",
        "unlabeled_probab = model.predict_proba(X_unlabeled)\n",
        "\n",
        "# High confidence threshold\n",
        "confidence = 0.9\n",
        "confidence_index = np.where(np.max(unlabeled_probab, axis=1) > confidence)[0]\n",
        "y_temp = unlabeled_pred[confidence_index]\n",
        "X_temp = X_unlabeled[confidence_index]\n",
        "\n",
        "# Retraining model on entire dataset\n",
        "X_combined = vstack((X_labeled, X_temp))\n",
        "y_combined = np.concatenate((y_labeled, y_temp))\n",
        "model.fit(X_combined, y_combined)\n",
        "\n",
        "# Predict labels for all the rows in the dataset\n",
        "comment_vectors_semi = vectoriser.transform(df['preprocessed text'])\n",
        "predictions = model.predict(comment_vectors_semi)\n",
        "\n",
        "label_map = {'objective': 0, 'subjective': 1}\n",
        "cluster_labels_semi = [label_map[label] for label in predictions]\n",
        "\n",
        "# Add the new column to the DataFrame\n",
        "df['Label Semi-Supervised'] = predictions"
      ],
      "metadata": {
        "id": "vxE2fpxVOxkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing semi-supervised to gold labels"
      ],
      "metadata": {
        "id": "Jmqy9oVGQ9Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Classification report for semi-supervised vs gold labels:\\n {classification_report(df['Gold Label'].iloc[:99], df['Label Semi-Supervised'].iloc[:99])}\")"
      ],
      "metadata": {
        "id": "nbJroXoiSeN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing clustering case 1 to to semi-supervised"
      ],
      "metadata": {
        "id": "UIxj4X04h1pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the same predictions between both cases\n",
        "matches_case_1_semi = (df['Label Clustering: Case 1'] == df['Label Semi-Supervised']).sum()\n",
        "\n",
        "# Calculating the percentage similarity\n",
        "percentage_similarity_case_1_semi = round((matches_case_1_semi / len(df)) * 100, 2)\n",
        "\n",
        "# Displaying the result\n",
        "print(f\"Percentage similarity between case 1 and semi-supervised: {percentage_similarity_case_1_semi}%\")"
      ],
      "metadata": {
        "id": "HCFw2-QPdcXh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "452d3acd-5177-47ed-e83e-d33e24d3be88"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Label Clustering: Case 1'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-cb07148a7c95>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Counting the same predictions between both cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmatches_case_1_semi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label Clustering: Case 1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label Semi-Supervised'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculating the percentage similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpercentage_similarity_case_1_semi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches_case_1_semi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Label Clustering: Case 1'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing clustering case 2 to to semi-supervised"
      ],
      "metadata": {
        "id": "IeN7Pm1Pilbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the same predictions between both cases\n",
        "matches_case_2_semi = (df['Label Clustering: Case 2'] == df['Label Semi-Supervised']).sum()\n",
        "\n",
        "# Calculating the percentage similarity\n",
        "percentage_similarity_case_2_semi = round((matches_case_2_semi / len(df)) * 100, 2)\n",
        "\n",
        "# Displaying the result\n",
        "print(f\"Percentage similarity between case 2 and semi-supervised: {percentage_similarity_case_2_semi}%\")"
      ],
      "metadata": {
        "id": "guhKjl_viTT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of labels in semi-supervised"
      ],
      "metadata": {
        "id": "EmxYze3KX70r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_semi = Counter(df['Label Semi-Supervised'])\n",
        "\n",
        "subjective_semi = count_semi['subjective']\n",
        "objective_semi = count_semi['objective']\n",
        "total_semi = subjective_semi + objective_semi\n",
        "\n",
        "subjective_percent_semi = round((subjective_semi / total_semi) * 100, 2)\n",
        "objective_percent_semi = round((objective_semi / total_semi) * 100, 2)"
      ],
      "metadata": {
        "id": "zgqMp487X-wM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "b9a9da2a-cb4a-41b9-fc09-56b2c708a2b0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Label Semi-Supervised'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-7483d7050a0f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount_semi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label Semi-Supervised'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubjective_semi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_semi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subjective'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mobjective_semi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_semi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'objective'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_semi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubjective_semi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobjective_semi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Label Semi-Supervised'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Subjective labels semi-supervised: {subjective_percent_semi}%\")\n",
        "print(f\"Objective labels semi-supervised: {objective_percent_semi}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaoVqTGrYhHI",
        "outputId": "39e98a11-7ffb-439c-d56e-911686ace1b9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjective labels semi-supervised: 98.37%\n",
            "Objective labels semi-supervised: 1.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective vs. subjective: Thread analysis"
      ],
      "metadata": {
        "id": "oa91_4kTjJ4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling thread structure"
      ],
      "metadata": {
        "id": "HijMVtVhoY2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threads_per_article = {}\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  # Defining features to be used for thread analysis\n",
        "  comment_id = row['comment_id']\n",
        "  parent_id = row['comment_parent_id']\n",
        "  comment_type = cluster_labels_case_2[index]\n",
        "  article_id = row['article_id']\n",
        "\n",
        "  if article_id not in threads_per_article:\n",
        "    threads_per_article[article_id] = {}\n",
        "\n",
        "  if pd.isnull(parent_id) or parent_id not in threads_per_article[article_id]:\n",
        "    threads_per_article[article_id][comment_id] = {'comment': preprocessed_text[index], 'replies': [], 'type': comment_type,\n",
        "                                                   'subjective_count': 0, 'objective_count': 0}\n",
        "  else:\n",
        "    parent_thread = threads_per_article[article_id][parent_id]\n",
        "    parent_thread['replies'].append({'comment': preprocessed_text[index], 'comment_id': comment_id, 'type': comment_type})\n",
        "\n",
        "for article_id, threads in threads_per_article.items():\n",
        "  for thread_id, thread in threads.items():\n",
        "    thread['subjective_count'] = sum(reply['type'] == 1 for reply in thread['replies'])\n",
        "    thread['objective_count'] = sum(reply['type'] == 0 for reply in thread['replies'])"
      ],
      "metadata": {
        "id": "UXHqauHsodql"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to assign the labels"
      ],
      "metadata": {
        "id": "L-LZkBvalBHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_comment_type(threads_per_article, comment_id, article_id):\n",
        "    if article_id not in threads_per_article or comment_id not in threads_per_article[article_id]:\n",
        "        return 'None'\n",
        "\n",
        "    thread = threads_per_article[article_id][comment_id]\n",
        "    subjective_count = thread['subjective_count']\n",
        "    objective_count = thread['objective_count']\n",
        "\n",
        "    if subjective_count > objective_count:\n",
        "        return 'subjective'\n",
        "    elif subjective_count < objective_count:\n",
        "        return 'objective'\n",
        "    else:\n",
        "        return 'subjective' if thread['type'] == 1 else 'objective'\n"
      ],
      "metadata": {
        "id": "0NUVqFMTj5-e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asigning labels based on replies"
      ],
      "metadata": {
        "id": "KIKQixQ9lEDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label Thread'] = df.apply(lambda row: predict_comment_type(threads_per_article, row['comment_id'], row['article_id']), axis=1)"
      ],
      "metadata": {
        "id": "y591O2Ygj_w2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing thread analysis to gold labels"
      ],
      "metadata": {
        "id": "Mx6CWeS-IkOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Classification report for semi-supervised vs gold labels:\\n {classification_report(df['Gold Label'].iloc[:99], df['Label Thread'].iloc[:99])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E9YABuiIiQc",
        "outputId": "70dbf615-4911-4326-dab8-b41cb8f1dc0c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for semi-supervised vs gold labels:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        None       0.00      0.00      0.00         0\n",
            "   objective       0.41      0.29      0.34        42\n",
            "  subjective       0.61      0.40      0.48        57\n",
            "\n",
            "    accuracy                           0.35        99\n",
            "   macro avg       0.34      0.23      0.27        99\n",
            "weighted avg       0.52      0.35      0.42        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing thread analysis to clustering case 1 labels"
      ],
      "metadata": {
        "id": "98AGvX7_oob3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the same predictions between both cases\n",
        "matches_thread_1 = (df['Label Clustering: Case 1'] == df['Label Thread']).sum()\n",
        "\n",
        "# Calculating the percentage similarity\n",
        "percentage_similarity_thread_1 = round((matches_thread_1 / len(df)) * 100, 2)\n",
        "\n",
        "# Displaying the result\n",
        "print(f\"Percentage similarity between clustering case 1 and thread analysis: {percentage_similarity_thread_1}%\")"
      ],
      "metadata": {
        "id": "TLcmuXcYolqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c1975b-95e9-4edc-f251-652bfba64c20"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage similarity between clustering case 1 and thread analysis: 29.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing thread analysis to clustering case 2 labels"
      ],
      "metadata": {
        "id": "MmVC4DXAmdsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the same predictions between both cases\n",
        "matches_thread_2 = (df['Label Clustering: Case 2'] == df['Label Thread']).sum()\n",
        "\n",
        "# Calculating the percentage similarity\n",
        "percentage_similarity_thread_2 = round((matches_thread_2 / len(df)) * 100, 2)\n",
        "\n",
        "# Displaying the result\n",
        "print(f\"Percentage similarity between case 2 and thread analysis: {percentage_similarity_thread_2}%\")"
      ],
      "metadata": {
        "id": "cNDJTjWfmC71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e024b5-51cc-43bc-d6ec-604023fbadff"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage similarity between case 2 and thread analysis: 56.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing thread analysis to semi-supervised labels"
      ],
      "metadata": {
        "id": "jDEWqAq8oynG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the same predictions between both cases\n",
        "matches_thread_semi = (df['Label Semi-Supervised'] == df['Label Thread']).sum()\n",
        "\n",
        "# Calculating the percentage similarity\n",
        "percentage_similarity_thread_semi = round((matches_thread_semi / len(df)) * 100, 2)\n",
        "\n",
        "# Displaying the result\n",
        "print(f\"Percentage similarity between semi-supervised and thread analysis: {percentage_similarity_thread_semi}%\")"
      ],
      "metadata": {
        "id": "WW0YGaYbo46b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c329025-1757-4019-94ee-db6204c3755e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage similarity between semi-supervised and thread analysis: 35.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "iZY-pyeaVaIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_opinion_counts = {}\n",
        "\n",
        "for article_id, threads in threads_per_article.items():\n",
        "  article_opinion_counts[article_id] = {'subjective': 0, 'objective': 0}\n",
        "  for thread_id, thread in threads.items():\n",
        "    article_opinion_counts[article_id]['subjective'] += thread['subjective_count']\n",
        "    article_opinion_counts[article_id]['objective'] += thread['objective_count']\n",
        "    article_opinion_counts[article_id]['subjective'] += 1 if thread['type'] == 1 else 0\n",
        "    article_opinion_counts[article_id]['objective'] += 1 if thread['type'] == 0 else 0\n",
        "\n",
        "summary = \"Discussion Summary:\\n\\n\"\n",
        "\n",
        "for article_id, threads in threads_per_article.items():\n",
        "  opinion_counts = article_opinion_counts[article_id]\n",
        "  total_opinions = opinion_counts['subjective'] + opinion_counts['objective']\n",
        "  perc_subjective = opinion_counts['subjective'] / total_opinions * 100\n",
        "  perc_objective = opinion_counts['objective'] / total_opinions * 100\n",
        "\n",
        "  summary += f\"Article ID: {article_id}\\n\"\n",
        "  summary += f\"Percentage of Subjective Opinions: {perc_subjective:.2f}%\\n\"\n",
        "  summary += f\"Percentage of Objective Opinions: {perc_objective:.2f}%\\n\\n\"\n",
        "\n",
        "  summary += \"Thread Analysis:\\n\"\n",
        "  for thread_id, thread in threads.items():\n",
        "    summary += f\"\\tParent Comment: {thread['comment']} (Type: {'Subjective' if thread['type'] == 1 else 'Objective'})\\n\"\n",
        "    summary += f\"\\t\\tSubjective Replies: {thread['subjective_count']}\\n\"\n",
        "    summary += f\"\\t\\tObjective Replies: {thread['objective_count']}\\n\"\n",
        "\n",
        "    for reply in thread['replies']:\n",
        "      summary += f\"\\t\\tReply Comment: {reply['comment']} (Type: {'Subjective' if reply['type'] == 1 else 'Objective'})\\n\"\n",
        "\n",
        "  summary += \"\\n\""
      ],
      "metadata": {
        "id": "NQjBBSAten3V"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/BSc AI Thesis/summary.txt\", \"w\") as file:\n",
        "    file.write(summary)"
      ],
      "metadata": {
        "id": "GLD2VZNW-bH8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df_master.head(100)"
      ],
      "metadata": {
        "id": "cjQiv7e1dfEi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.to_csv('/content/drive/MyDrive/Colab Notebooks/BSc AI Thesis/defense.csv', index=False)"
      ],
      "metadata": {
        "id": "ihpCSm1vdfXx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfH6x-Akd5yb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}